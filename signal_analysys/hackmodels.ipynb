{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 6405 6406 6408] pipe_sc_svc\n",
      "[   0    1    2 ... 6405 6406 6407] pipe_sc_svc\n",
      "[   2    3    4 ... 6406 6407 6408] pipe_sc_svc\n",
      "[   0    1    2 ... 6404 6407 6408] pipe_sc_svc\n",
      "[   0    1    4 ... 6406 6407 6408] pipe_sc_svc\n",
      "   pipe_sc_svc\n",
      "0     0.910296\n",
      "1     0.919657\n",
      "2     0.914197\n",
      "3     0.919657\n",
      "4     0.918813\n",
      "pipe_sc_svc    0.916524\n",
      "dtype: float64\n",
      "Classification Report for pipe_sc_svc\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      1479\n",
      "           1       1.00      0.03      0.06       124\n",
      "\n",
      "    accuracy                           0.93      1603\n",
      "   macro avg       0.96      0.52      0.51      1603\n",
      "weighted avg       0.93      0.93      0.89      1603\n",
      "\n",
      "F1-Score for pipe_sc_svc: 0.0625\n",
      "      Pipeline  F1-Score\n",
      "0  pipe_sc_svc    0.0625\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer # tri druhy skalovani\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split # pro rozdeleni  dat\n",
    "from sklearn.model_selection import KFold # pouziti cross validace\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "df_final = pd.read_csv('final_dataset2.csv')\n",
    "\n",
    "seed = 420\n",
    "y = preprocessing.LabelEncoder().fit_transform(df_final['art_annotation'])\n",
    "\n",
    "X = df_final\n",
    "X = X.drop('art_annotation',axis = 1)\n",
    "X = X.drop('icp_annotation',axis = 1)\n",
    "X = X.drop('StartTime',axis = 1)\n",
    "X = X.drop('EndTime',axis = 1)\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)\n",
    "\n",
    "\n",
    "pipe_mm_rf200 = Pipeline([('scaler', MinMaxScaler()),('classifier', RandomForestClassifier(n_estimators=200))])\n",
    "pipe_mm_rf500 = Pipeline([('scaler', MinMaxScaler()),('classifier', RandomForestClassifier(n_estimators=500))])\n",
    "pipe_mm_knn5 = Pipeline([('scaler', MinMaxScaler()),('classifier', KNeighborsClassifier(n_neighbors=5))])\n",
    "pipe_mm_knn7 = Pipeline([('scaler', MinMaxScaler()),('classifier', KNeighborsClassifier(n_neighbors=7))])\n",
    "pipe_mm_knn9 = Pipeline([('scaler', MinMaxScaler()),('classifier', KNeighborsClassifier(n_neighbors=9))])\n",
    "#pipe_mm_xcb = Pipeline([('scaler', MinMaxScaler()),('classifier', xgb.XGBClassifier())]) #n_estimators=500, max_depth=16) choose hyperparameters correctly?\n",
    "#pipe_mm_cat = Pipeline([('scaler', MinMaxScaler()),('classifier', cb.CatBoostClassifier(random_state=seed, verbose = 0))])\n",
    "pipe_sc_svc = Pipeline([('scaler', StandardScaler()),('classifier', SVC(gamma='auto', cache_size=4000, C=0.8))])\n",
    "\n",
    "pipes = {\"pipe_sc_svc\":pipe_sc_svc}\n",
    "\n",
    "\n",
    "# pro kazdou rouru si budeme drzet vysledky\n",
    "results = { pipe_name: [] for pipe_name in pipes.keys()}\n",
    "# rozdelime si data na trenovaci, ktere budeme delit dale, a testovaci, na kterych pak ukazeme chovani\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X,y, test_size=0.2,random_state=seed) # testovaci data zatim nepouzijeme\n",
    "# trenovaci mnozinu budeme delit dale na 5 podmnozin\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "for train_index, test_index in kf.split(X_tr, y_tr): # vraci dvojici poli testovacich a trenovacich indexu\n",
    "  # rozdel si data na trenovaci a na data, na kterych bude ohodnocen klasifikator\n",
    "  X_fold_tr = X_tr.values[train_index]\n",
    "  y_fold_tr = y_tr[train_index]\n",
    "  X_fold_test = X_tr.values[test_index]\n",
    "  y_fold_test = y_tr[test_index]\n",
    "  for k, pipe in pipes.items(): # pro kazdou pipe, delej\n",
    "    pipe.fit(X_fold_tr, y_fold_tr) # nauc\n",
    "    results[k].append(pipe.score(X_fold_test,y_fold_test)) # uloz si accuracy\n",
    "    print(train_index,k)\n",
    "#udelej si dataframe pro zhodnoceni\n",
    "results = pd.DataFrame(data = results)\n",
    "print(results) # tiskni za jednoltive foldy uspesnost klasifikatoru\n",
    "print(results.mean()) # tiskni prumer\n",
    "\n",
    "f1_results = {}\n",
    "\n",
    "# Add the classification report and F1-score\n",
    "for k, pipe in pipes.items():\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "    y_pred_test = pipe.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred_test)  # You can change 'weighted' based on your requirement\n",
    "    f1_results[k] = f1  # Store the F1-score\n",
    "    \n",
    "    print(f\"Classification Report for {k}\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    print(f\"F1-Score for {k}: {f1}\")\n",
    "\n",
    "# Convert F1-score results to DataFrame for better visualization\n",
    "f1_results_df = pd.DataFrame(list(f1_results.items()), columns=['Pipeline', 'F1-Score'])\n",
    "print(f1_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    2    3 ... 6406 6407 6408] pipe_sc_svc\n",
      "[   0    2    3 ... 6406 6407 6408] pipe_mm_isoforest\n",
      "[   0    1    2 ... 6406 6407 6408] pipe_sc_svc\n",
      "[   0    1    2 ... 6406 6407 6408] pipe_mm_isoforest\n",
      "[   0    1    2 ... 6405 6406 6407] pipe_sc_svc\n",
      "[   0    1    2 ... 6405 6406 6407] pipe_mm_isoforest\n",
      "[   0    1    3 ... 6405 6406 6408] pipe_sc_svc\n",
      "[   0    1    3 ... 6405 6406 6408] pipe_mm_isoforest\n",
      "[   1    2    4 ... 6405 6407 6408] pipe_sc_svc\n",
      "[   1    2    4 ... 6405 6407 6408] pipe_mm_isoforest\n",
      "   pipe_sc_svc  pipe_mm_isoforest\n",
      "0     0.903276           0.916537\n",
      "1     0.917317           0.923557\n",
      "2     0.913417           0.913417\n",
      "3     0.910296           0.915757\n",
      "4     0.932865           0.928962\n",
      "pipe_sc_svc          0.915434\n",
      "pipe_mm_isoforest    0.919646\n",
      "dtype: float64\n",
      "Classification Report for pipe_sc_svc\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      1479\n",
      "           1       1.00      0.03      0.06       124\n",
      "\n",
      "    accuracy                           0.93      1603\n",
      "   macro avg       0.96      0.52      0.51      1603\n",
      "weighted avg       0.93      0.93      0.89      1603\n",
      "\n",
      "F1-Score for pipe_sc_svc: 0.0625\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\HP GAMING\\Desktop\\Hackithon2023\\hackmodels.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP%20GAMING/Desktop/Hackithon2023/hackmodels.ipynb#W1sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m pipe\u001b[39m.\u001b[39mfit(X_tr, y_tr)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP%20GAMING/Desktop/Hackithon2023/hackmodels.ipynb#W1sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m y_pred_test \u001b[39m=\u001b[39m pipe\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/HP%20GAMING/Desktop/Hackithon2023/hackmodels.ipynb#W1sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m f1 \u001b[39m=\u001b[39m f1_score(y_test, y_pred_test)  \u001b[39m# You can change 'weighted' based on your requirement\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP%20GAMING/Desktop/Hackithon2023/hackmodels.ipynb#W1sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m f1_results[k] \u001b[39m=\u001b[39m f1  \u001b[39m# Store the F1-score\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP%20GAMING/Desktop/Hackithon2023/hackmodels.ipynb#W1sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mClassification Report for \u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP GAMING\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1146\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf1_score\u001b[39m(\n\u001b[0;32m   1012\u001b[0m     y_true,\n\u001b[0;32m   1013\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1020\u001b[0m ):\n\u001b[0;32m   1021\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \n\u001b[0;32m   1023\u001b[0m \u001b[39m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[39m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1146\u001b[0m     \u001b[39mreturn\u001b[39;00m fbeta_score(\n\u001b[0;32m   1147\u001b[0m         y_true,\n\u001b[0;32m   1148\u001b[0m         y_pred,\n\u001b[0;32m   1149\u001b[0m         beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   1150\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1151\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1152\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1153\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1154\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1155\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\HP GAMING\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1287\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfbeta_score\u001b[39m(\n\u001b[0;32m   1159\u001b[0m     y_true,\n\u001b[0;32m   1160\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1167\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1168\u001b[0m ):\n\u001b[0;32m   1169\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \n\u001b[0;32m   1171\u001b[0m \u001b[39m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1284\u001b[0m \u001b[39m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   1288\u001b[0m         y_true,\n\u001b[0;32m   1289\u001b[0m         y_pred,\n\u001b[0;32m   1290\u001b[0m         beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[0;32m   1291\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1292\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1293\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1294\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   1295\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1296\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1297\u001b[0m     )\n\u001b[0;32m   1298\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[1;32mc:\\Users\\HP GAMING\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1572\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1573\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1575\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\HP GAMING\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1391\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1389\u001b[0m         \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1390\u001b[0m             average_options\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1392\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTarget is \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m but average=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1393\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mchoose another average setting, one of \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1394\u001b[0m         )\n\u001b[0;32m   1395\u001b[0m \u001b[39melif\u001b[39;00m pos_label \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m):\n\u001b[0;32m   1396\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1397\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNote that pos_label (set to \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) is ignored when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maverage != \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m). You may use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1401\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[0;32m   1402\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Add Isolation Forest to your existing pipelines\n",
    "pipe_mm_isoforest = Pipeline([('scaler', MinMaxScaler()),('classifier', IsolationForest(contamination=0.01))])\n",
    "\n",
    "# Add the new pipeline to your existing list\n",
    "pipes = {\"pipe_sc_svc\": pipe_sc_svc, \"pipe_mm_isoforest\": pipe_mm_isoforest}\n",
    "# pro kazdou rouru si budeme drzet vysledky\n",
    "results = { pipe_name: [] for pipe_name in pipes.keys()}\n",
    "# rozdelime si data na trenovaci, ktere budeme delit dale, a testovaci, na kterych pak ukazeme chovani\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X,y, test_size=0.2,random_state=seed) # testovaci data zatim nepouzijeme\n",
    "# trenovaci mnozinu budeme delit dale na 5 podmnozin\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "for train_index, test_index in kf.split(X_tr, y_tr):\n",
    "    X_fold_tr = X_tr.values[train_index]\n",
    "    y_fold_tr = y_tr[train_index]\n",
    "    X_fold_test = X_tr.values[test_index]\n",
    "    y_fold_test = y_tr[test_index]\n",
    "    \n",
    "    for k, pipe in pipes.items():\n",
    "        pipe.fit(X_fold_tr, y_fold_tr)\n",
    "        \n",
    "        if isinstance(pipe.named_steps['classifier'], IsolationForest):\n",
    "            y_pred = pipe.predict(X_fold_test)\n",
    "            y_pred = [1 if x == -1 else 0 for x in y_pred]  # Convert -1 to 1 for anomaly, and 1 to 0 for normal\n",
    "            acc = sum(y_fold_test == y_pred) / len(y_fold_test)\n",
    "            results[k].append(acc)\n",
    "        else:\n",
    "            results[k].append(pipe.score(X_fold_test, y_fold_test))\n",
    "        \n",
    "        print(train_index, k)\n",
    "\n",
    "#udelej si dataframe pro zhodnoceni\n",
    "results = pd.DataFrame(data = results)\n",
    "print(results) # tiskni za jednoltive foldy uspesnost klasifikatoru\n",
    "print(results.mean()) # tiskni prumer\n",
    "\n",
    "f1_results = {}\n",
    "\n",
    "# Add the classification report and F1-score\n",
    "for k, pipe in pipes.items():\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "    y_pred_test = pipe.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred_test)  # You can change 'weighted' based on your requirement\n",
    "    f1_results[k] = f1  # Store the F1-score\n",
    "    \n",
    "    print(f\"Classification Report for {k}\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    print(f\"F1-Score for {k}: {f1}\")\n",
    "\n",
    "# Convert F1-score results to DataFrame for better visualization\n",
    "f1_results_df = pd.DataFrame(list(f1_results.items()), columns=['Pipeline', 'F1-Score'])\n",
    "print(f1_results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
